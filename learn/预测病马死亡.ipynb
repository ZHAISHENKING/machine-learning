{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = pd.read_table('./data/horseColicTraining.txt',header=None)\n",
    "part2 = pd.read_table('./data/horseColicTest.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先把所有数据级联到一起\n",
    "samples = pd.concat((part1,part2))\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = samples.values[:,:-1]\n",
    "target = samples.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366, 21), (366,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. ,  1. , 38.5, 66. , 28. ,  3. ,  3. ,  0. ,  2. ,  5. ,  4. ,\n",
       "        4. ,  0. ,  0. ,  0. ,  3. ,  5. , 45. ,  8.4,  0. ,  0. ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先对数据进行映射，然后再进行特征预处理\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer\n",
    "\n",
    "train1 = StandardScaler().fit_transform(train)\n",
    "train2 = MinMaxScaler().fit_transform(train)\n",
    "train3 = Normalizer().fit_transform(train)\n",
    "\n",
    "trains = [train1,train2,train3]\n",
    "feature_project_names = ['StandardScaler','MinMaxScaler','Normalizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 预测不同的特征处理，对算法的影响\n",
    "# 使用此函数找到一个好的特征处理方案\n",
    "def score_with_model(model,trains,target,feature_project_names):\n",
    "    for i,train in enumerate(trains):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(train,target,random_state=1)\n",
    "        score = model.fit(X_train,y_train).score(X_test,y_test)\n",
    "        print(\"{} 特征处理{} 得分:{}\".format(model.__class__.__name__,feature_project_names[i],score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 特征处理StandardScaler 得分:0.6739130434782609\n",
      "KNeighborsClassifier 特征处理MinMaxScaler 得分:0.6847826086956522\n",
      "KNeighborsClassifier 特征处理Normalizer 得分:0.7065217391304348\n"
     ]
    }
   ],
   "source": [
    "score_with_model(KNeighborsClassifier(),trains,target,feature_project_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 特征处理StandardScaler 得分:0.6521739130434783\n",
      "LogisticRegression 特征处理MinMaxScaler 得分:0.6630434782608695\n",
      "LogisticRegression 特征处理Normalizer 得分:0.6304347826086957\n"
     ]
    }
   ],
   "source": [
    "score_with_model(LogisticRegression(),trains,target,feature_project_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 特征处理StandardScaler 得分:0.6630434782608695\n",
      "DecisionTreeClassifier 特征处理MinMaxScaler 得分:0.6304347826086957\n",
      "DecisionTreeClassifier 特征处理Normalizer 得分:0.6195652173913043\n"
     ]
    }
   ],
   "source": [
    "score_with_model(DecisionTreeClassifier(),trains,target,feature_project_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 特征处理StandardScaler 得分:0.7282608695652174\n",
      "SVC 特征处理MinMaxScaler 得分:0.6847826086956522\n",
      "SVC 特征处理Normalizer 得分:0.5869565217391305\n"
     ]
    }
   ],
   "source": [
    "score_with_model(SVC(),trains,target,feature_project_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证，获得好的算法\n",
    "# 先使用MinMaxScaler处理\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def select_best_model(model,train,target):\n",
    "    kfold = KFold(n_splits=10)\n",
    "    results = cross_val_score(model,train,target,cv=kfold)\n",
    "    print(\"{}算法 平均值是{}，方差是{}，最大值{},最小值{}\".format(model.__class__.__name__,results.mean(),results.std(),results.max(),results.min()))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier算法 平均值是0.6554804804804805，方差是0.06615852287004709，最大值0.7837837837837838,最小值0.5555555555555556\n",
      "[0.78378378 0.67567568 0.7027027  0.59459459 0.64864865 0.62162162\n",
      " 0.58333333 0.55555556 0.66666667 0.72222222]\n"
     ]
    }
   ],
   "source": [
    "select_best_model(KNeighborsClassifier(),train2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression算法 平均值是0.6940690690690691，方差是0.06473652809907691，最大值0.8611111111111112,最小值0.6111111111111112\n",
      "[0.7027027  0.64864865 0.7027027  0.7027027  0.72972973 0.64864865\n",
      " 0.66666667 0.66666667 0.86111111 0.61111111]\n"
     ]
    }
   ],
   "source": [
    "select_best_model(LogisticRegression(),train2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier算法 平均值是0.6721471471471472，方差是0.06484248619913455，最大值0.8055555555555556,最小值0.5675675675675675\n",
      "[0.56756757 0.67567568 0.7027027  0.67567568 0.72972973 0.67567568\n",
      " 0.63888889 0.80555556 0.66666667 0.58333333]\n"
     ]
    }
   ],
   "source": [
    "select_best_model(DecisionTreeClassifier(),train2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC算法 平均值是0.7183933933933934，方差是0.059556305165923036，最大值0.8108108108108109,最小值0.6388888888888888\n",
      "[0.67567568 0.72972973 0.81081081 0.75675676 0.75675676 0.64864865\n",
      " 0.66666667 0.63888889 0.80555556 0.69444444]\n"
     ]
    }
   ],
   "source": [
    "select_best_model(SVC(),train2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分样本集\n",
    "X_train,X_test,y_train,y_test = train_test_split(train2,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear', 'rbf', 'poly'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 综合考虑，选择SVC算法，使用标准化对数据特征进行预处理\n",
    "# 算法调参，使用GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "param_dic = {\n",
    "    'kernel':['linear','rbf','poly'],\n",
    "    'C':[0.001,0.01,0.1,1,10,100],\n",
    "    'gamma':np.arange(0,100,10)\n",
    "}\n",
    "\n",
    "gridCV = GridSearchCV(svc,param_grid=param_dic)\n",
    "\n",
    "gridCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc = gridCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567567567567568"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027027027027027"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train,target,test_size=0.1)\n",
    "SVC(C=0.001,kernel='poly',gamma=10).fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征没选好，原始数据比特征处理过的数据表现要好\n",
    "# 特征选择\n",
    "# 降维\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为要使用lda进行有监督的降维处理，所以，先使用pca查看大概有多少个特征起主导作用\n",
    "train4 = PCA(n_components=0.97).fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5135135135135135"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train4,target,test_size=0.1)\n",
    "SVC(C=0.001,kernel='rbf',gamma=10).fit(X_train,y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837837837837838"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train4,target,test_size=0.1)\n",
    "SVC().fit(X_train,y_train).score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
